{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "swedish-carolina",
   "metadata": {},
   "source": [
    "# Build and train A Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-mouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "cwd = os.getcwd()\n",
    "#add CIFAR10 data in the environment\n",
    "sys.path.append(cwd + '/../cifar10') \n",
    "\n",
    "#Numpy is linear algebra lbrary\n",
    "import numpy as np\n",
    "# Matplotlib is a visualizations library \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import utils\n",
    "from torchvision import transforms\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "\n",
    "def load_data():\n",
    "    \n",
    "    #convert the images to tensor and normalized them\n",
    "    transform = transforms.Compose([\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=1)\n",
    "    return trainloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-console",
   "metadata": {},
   "source": [
    "## Utility functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vectors_to_images(vectors):\n",
    "    return vectors.view(vectors.size(0), 3, 32, 32)\n",
    "\n",
    "def log_images(images, num_images, format='NCHW', normalize=True):\n",
    "    '''\n",
    "    input images are expected in format (NCHW)\n",
    "    '''\n",
    "    if type(images) == np.ndarray:\n",
    "        images = torch.from_numpy(images)\n",
    "\n",
    "    if format == 'NHWC':\n",
    "        images = images.transpose(1, 3)\n",
    "\n",
    "    # Make horizontal grid from image tensor\n",
    "    horizontal_grid = vutils.make_grid(\n",
    "        images, normalize=normalize, scale_each=True)\n",
    "    # Make vertical grid from image tensor\n",
    "    nrows = int(np.sqrt(num_images))\n",
    "    grid = vutils.make_grid(\n",
    "        images, nrow=nrows, normalize=True, scale_each=True)\n",
    "\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 16))\n",
    "    plt.imshow(np.moveaxis(horizontal_grid.numpy(), 0, -1))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-ordering",
   "metadata": {},
   "source": [
    "## Generator and Discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-semester",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DiscriminatorNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A three hidden-layer discriminative neural network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorNet, self).__init__()\n",
    "        n_features = 3072\n",
    "        n_out = 1\n",
    "\n",
    "        self.hidden0 = nn.Sequential(\n",
    "            nn.Linear(n_features, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.out = nn.Sequential(\n",
    "            torch.nn.Linear(256, n_out),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GeneratorNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A three hidden-layer generative neural network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(GeneratorNet, self).__init__()\n",
    "        n_features = 100\n",
    "        n_out = 3072\n",
    "\n",
    "        self.hidden0 = nn.Sequential(\n",
    "            nn.Linear(n_features, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(1024, n_out),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "isolated-myanmar",
   "metadata": {},
   "source": [
    "## Train a GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(discriminator, optimizer, real_data, fake_data, loss):\n",
    "    N = real_data.size(0)\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Train on Real Data\n",
    "    prediction_real = discriminator(real_data)\n",
    "    # Calculate error and backpropagate\n",
    "    error_real = loss(prediction_real, Variable(torch.ones(N, 1)))\n",
    "    error_real.backward()\n",
    "\n",
    "    # Train on Fake Data\n",
    "    prediction_fake = discriminator(fake_data)\n",
    "    # Calculate error and backpropagate\n",
    "    error_fake = loss(prediction_fake, Variable(torch.zeros(N, 1)))\n",
    "    error_fake.backward()\n",
    "\n",
    "    # Update weights with gradients\n",
    "    optimizer.step()\n",
    "\n",
    "    # Return error and predictions for real and fake inputs\n",
    "    return error_real + error_fake, prediction_real, prediction_fake\n",
    "\n",
    "\n",
    "def train_generator(discriminator, optimizer, fake_data, loss):\n",
    "    # Reset gradients\n",
    "    N = fake_data.size(0)  \n",
    "    \n",
    "    # Sample noise and generate fake data\n",
    "    optimizer.zero_grad()  \n",
    "    \n",
    "    # Calculate error and backpropagate\n",
    "    prediction = discriminator(fake_data)  \n",
    "    error = loss(prediction, Variable(torch.ones(N, 1)))\n",
    "    \n",
    "    # Update weights with gradients\n",
    "    error.backward()  \n",
    "    optimizer.step()  \n",
    "    \n",
    "    # Return error\n",
    "    return error\n",
    "\n",
    "\n",
    "def train():\n",
    "\n",
    "    # Models, optimizers and losses\n",
    "    discriminator = DiscriminatorNet()\n",
    "    generator = GeneratorNet()\n",
    "    loss_d = nn.BCELoss()\n",
    "    loss_g = nn.BCELoss()\n",
    "    d_optimizer = optim.Adam(discriminator.parameters(), 0.0002)\n",
    "    g_optimizer = optim.Adam(generator.parameters(), 0.0002)\n",
    "\n",
    "    data_loader= load_data()\n",
    "    \n",
    "    num_epochs=1\n",
    "    num_batches = len(data_loader)\n",
    "    \n",
    "    num_test_samples = 48\n",
    "    test_noise = Variable(torch.randn(num_test_samples, 100))\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for n_batch, data in enumerate(data_loader):\n",
    "\n",
    "            (real_batch, labels) = data\n",
    "            N = real_batch.size(0)\n",
    "\n",
    "            # 1. Train Discriminator\n",
    "            real_data = real_batch.view(N, -1)\n",
    "\n",
    "            # Generate fake data and detach so gradients are not calculated for generator)\n",
    "            latent_space_data = Variable(torch.randn(N, 100))\n",
    "            fake_data = generator(latent_space_data).detach()\n",
    "\n",
    "            d_error, d_pred_real, d_pred_fake = train_discriminator(discriminator, d_optimizer, real_data,\n",
    "                                                                          fake_data,\n",
    "                                                                          loss_d)\n",
    "            # 2. Train Generator\n",
    "\n",
    "            # Generate fake data TO train Generator\n",
    "            latent_space_data = Variable(torch.randn(N, 100))\n",
    "            fake_data = generator(latent_space_data)\n",
    "            # Train G\n",
    "            g_error = train_generator(discriminator, g_optimizer, fake_data, loss_g)  # Log batch error\n",
    "\n",
    "            \n",
    "            if n_batch % 50 == 0:\n",
    "                print('Epoch: [{}/{}], Batch Num: [{}/{}]'.format(\n",
    "                            epoch, num_epochs, n_batch, num_batches)\n",
    "                    )\n",
    "                print('Discriminator Loss: {:.4f}, Generator Loss: {:.4f}'.format(d_error, g_error))\n",
    "                print('D(x): {:.4f}, D(G(z)): {:.4f}'.format(d_pred_real.mean(), d_pred_fake.mean()))\n",
    "                print('------------------------------')\n",
    "                \n",
    "              \n",
    "    \n",
    "    print('Training finished')\n",
    "    \n",
    "    #Generate images\n",
    "    test_images = vectors_to_images(generator(test_noise))\n",
    "    test_images = test_images.data\n",
    "    log_images(test_images,test_images.size()[0])\n",
    "    \n",
    "train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
