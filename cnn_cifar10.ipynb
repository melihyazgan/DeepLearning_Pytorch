{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train a Convolutional Neural Network\n",
    "We will build a fully functional CNN and train it with our familiar CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import utils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img):\n",
    "    # unnormalize the image\n",
    "    img = img/2+0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "def load_data():\n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "    batch_size=4\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=1)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=1)\n",
    "    return trainloader, testloader\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define CNN\n",
    "CNN Structure will be:\n",
    "- A conv layer with 3 channels as input, 6 channels as output, and a 5x5 kernel\n",
    "- A 2x2 max-pooling layer\n",
    "- A conv layer with 6 channels as input, 16 channels as output, and a 5x5 kernel\n",
    "- A linear layer with 1655 nodes\n",
    "- A linear layer with 120 nodes\n",
    "- A linear layer with 84 nodes\n",
    "- A linear layer with 10 nodes\n",
    "Activation is RELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 =nn.Conv2d(3,6,5)\n",
    "        self.pool=nn.MaxPool2d(2,2)\n",
    "        self.conv2=nn.Conv2d(6,16,5)\n",
    "        self.fc1= nn.Linear(16*5*5,120)\n",
    "        self.fc2= nn.Linear(120,84)\n",
    "        self.fc3= nn.Linear(84,10)\n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x,1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "def train(model,train_loader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for epoch in range(2): # loop over the dataset multiple times\n",
    "        for i, data in enumerate(train_loader,0):\n",
    "            #GPU\n",
    "            inputs, labels = data[0].to(device),data[1].to(device)\n",
    "            #CPU\n",
    "            #inputs, labels = data\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i %2000 == 1999:\n",
    "                print(\"[{} {}] loss: {}\".format(epoch+1,i+1,running_loss/2000))\n",
    "                running_loss=0\n",
    "    print('Finished Training')\n",
    "    print('Saving')\n",
    "    PATH = './cifar_net.pth'\n",
    "    torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data,test_data = load_data()\n",
    "model = CNN()\n",
    "#GPU\n",
    "#model.to(device)\n",
    "train(model, training_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need to load back your saved model. It is not neccessary here but written for info\n",
    "#PATH = './cifar_net.pth'\n",
    "#model = CNN()\n",
    "#model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(training_data)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "show_image(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get random test images \n",
    "dataiter = iter(test_data)\n",
    "images, labels = next(dataiter)\n",
    "show_image(utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "# print images\n",
    "\n",
    "outputs = model(images)\n",
    "    \n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in test_data:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on test images: {100 * correct // total} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "255a7a788dfa8cd0882136c3c7c1db6788512aae5db4a09097de83813919f776"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
